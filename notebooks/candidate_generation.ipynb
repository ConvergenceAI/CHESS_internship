{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook we will test the candidate generation module "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34686225f362ebe2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTs\n",
    "from utils.task import Task\n",
    "import json\n",
    "import os\n",
    "from src.pipeline.candidate_generation import candidate_generation\n",
    "from utils.database_utils.db_info import get_db_schema\n",
    "from dotenv import load_dotenv\n",
    "from utils.prompt import load_prompt\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T12:44:24.593369Z",
     "start_time": "2024-08-23T12:44:23.078759Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to load JSON data\n",
    "def load_json_data(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Function to create task object\n",
    "def create_task(example):\n",
    "    return Task(example)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T12:44:24.598627Z",
     "start_time": "2024-08-23T12:44:24.594374Z"
    }
   },
   "id": "d00f7f5c7585baab",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load the task data\n",
    "filepath = \"C:/Users\\yousf\\Bureau\\ConvergenceAI\\CHESS_Impl\\data/test/subsampled_test.json\"\n",
    "data = load_json_data(filepath)\n",
    "# load the retrieved entities\n",
    "filepath_entities = \"C:/Users\\yousf\\Bureau\\ConvergenceAI\\CHESS_Impl\\data/test/retrieved_entities.json\"\n",
    "retrieved_entities = load_json_data(filepath_entities)\n",
    "# load the retrieved context\n",
    "filepath_context = \"C:/Users\\yousf\\Bureau\\ConvergenceAI\\CHESS_Impl\\data/test/retrieved_context.json\"\n",
    "retrieved_context = load_json_data(filepath_context)\n",
    "# load the selected schema\n",
    "filepath_schema = \"C:/Users\\yousf\\Bureau\\ConvergenceAI\\CHESS_Impl\\data/test/selected_schema.json\"\n",
    "selected_schema = load_json_data(filepath_schema)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T12:44:24.607139Z",
     "start_time": "2024-08-23T12:44:24.599636Z"
    }
   },
   "id": "5ee82a0867e6ceaa",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'chain_of_thought_reasoning': \"To solve this query, I need to identify a school that meets several criteria: it must be a high school (EILCode = 'HS'), located in Merced county, provides Lunch Provision 2, and spans grades 9 to 12. First, I will filter schools based on these criteria. Since the database schema specifics are not provided, I assume there is a table for schools where I can find columns for EILCode, county, lunch provision, lowest grade, and highest grade. After filtering the schools based on these criteria, I will select the city location of the school. The query will involve selecting the city column from the schools table after applying the necessary WHERE conditions to filter by EILCode, county, lunch provision, and grade range. I will ensure to handle any potential NULL values in the columns used for filtering to avoid incorrect results.\",\n 'SQL': \"SELECT T1.city FROM Schools T1 WHERE T1.EILCode = 'HS' AND T1.county = 'Merced' AND T1.lunchProvision = 2 AND T1.lowestGrade = 9 AND T1.highestGrade = 12\"}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test candidate generation module with a random sample\n",
    "index = 1\n",
    "example = data[index]\n",
    "task = create_task(example)\n",
    "\n",
    "model = (\"gpt-4\")\n",
    "ans = candidate_generation(task=task, retrieved_entities=retrieved_entities[index],\n",
    "                           retrieved_context=retrieved_context[index], selected_schema=selected_schema[index],\n",
    "                           model=model,\n",
    "                           num_samples=1)\n",
    "ans"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T12:44:38.182585Z",
     "start_time": "2024-08-23T12:44:29.118696Z"
    }
   },
   "id": "fa2b90c2c3cd9c10",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:11, 11.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  {'chain_of_thought_reasoning': \"To answer the question, we need to identify the atom id associated with the molecule 'TR346' and count the distinct types of bonds that can be created by this molecule. First, we need to find the table that links molecules to their atom ids, which is likely a molecule table and an atom table. We assume there's a relationship table that connects molecules to atoms, possibly named 'molecule_atoms'. Next, we need to find the table that contains information about bonds, which might be named 'bonds' or similar, and it should relate to atoms. We will join these tables based on molecule id and atom id. We will filter the molecule by its name 'TR346', count the distinct bond types, and list the atom ids. The SQL query will involve selecting the atom id from the joined table of molecules and atoms, and a subquery or a separate count on the bond types, grouped by the molecule id.\", 'SQL': \"SELECT T1.atom_id, COUNT(DISTINCT T3.bond_type) AS bond_type_count FROM molecule_atoms T1 JOIN molecules T2 ON T1.molecule_id = T2.molecule_id JOIN bonds T3 ON T1.atom_id = T3.atom_id WHERE T2.molecule_name = 'TR346' GROUP BY T2.molecule_id\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:20,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :  {'chain_of_thought_reasoning': \"To answer the question, I need to identify a school that meets several criteria: it must be a high school (EILCode = 'HS'), located in Merced county, with Lunch Provision 2, and it should cover grades from 9 to 12. First, I will filter the schools based on these criteria. Since the question specifically asks for the city location, I will select only the city column from the relevant table. I will use aliases for clarity in the query and ensure that the columns used for filtering (like grades and EILCode) do not contain null values to avoid incorrect data filtering.\", 'SQL': \"SELECT T1.city FROM Schools AS T1 WHERE T1.EILCode = 'HS' AND T1.county = 'Merced' AND T1.LunchProvision = 2 AND T1.lowestGrade = 9 AND T1.highestGrade = 12\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:29,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 :  {'chain_of_thought_reasoning': \"To answer the question, I need to find the tallest hero from the 'Marvel Comics' publisher. First, I will identify the relevant tables and columns: heroes and publishers. The heroes table likely contains columns for hero names and heights, while the publishers table contains publisher names. I will join these tables on the publisher ID to access both hero details and publisher information. Using the WHERE clause, I will filter heroes published by 'Marvel Comics'. To find the tallest hero, I will sort the heroes by height in descending order and use LIMIT 1 to get the top result. The SELECT clause will only include the hero's full name, as per the question's requirement.\", 'SQL': \"SELECT T1.full_name FROM heroes T1 JOIN publishers T2 ON T1.publisher_id = T2.id WHERE T2.publisher_name = 'Marvel Comics' AND T1.height_cm IS NOT NULL ORDER BY T1.height_cm DESC LIMIT 1\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:39,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 :  {'chain_of_thought_reasoning': \"To answer the question, I need to count the number of elders who have obtained the 'Supporter' badge. First, I identify the relevant tables and columns: a table likely named 'users' or similar for user data including age, and a table for badges which might be named 'badges'. There should also be a linking table, possibly named 'user_badges', that connects users with the badges they've obtained. The steps are: 1) Join the 'users' table with the 'user_badges' table to link users with their badges. 2) Join the result with the 'badges' table to filter by the 'Supporter' badge. 3) Filter users where age is greater than 65. 4) Count the distinct users who meet these criteria. I will use aliases for clarity in the query and ensure to filter out any null values in relevant columns to avoid incorrect calculations.\", 'SQL': \"SELECT COUNT(DISTINCT T1.user_id) FROM users T1 JOIN user_badges T2 ON T1.id = T2.user_id JOIN badges T3 ON T2.badge_id = T3.id WHERE T1.age > 65 AND T3.name = 'Supporter' AND T1.age IS NOT NULL AND T3.name IS NOT NULL\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:49,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 :  {'chain_of_thought_reasoning': \"To answer the question, I need to identify users from New York who have both 'Teacher' and 'Supporter' badges. First, I'll need to join the tables that contain user information, location, and badges. Assuming there are tables named 'Users', 'Badges', and 'UserBadges' where 'Users' contains user and location information, 'Badges' contains badge names, and 'UserBadges' links users with their badges. I will filter users based on the 'New York' location. Then, I'll join the 'UserBadges' table to get the badges of these users and further join the 'Badges' table to filter only those badges that are 'Teacher' and 'Supporter'. I will group the results by user and count the distinct badges, ensuring that only users with both badges are counted. Finally, I will count the number of such users.\", 'SQL': \"SELECT COUNT(DISTINCT T1.UserId) FROM Users T1 JOIN UserBadges T2 ON T1.UserId = T2.UserId JOIN Badges T3 ON T2.BadgeId = T3.BadgeId WHERE T1.Location = 'New York' AND T3.Name IN ('Teacher', 'Supporter') GROUP BY T1.UserId HAVING COUNT(DISTINCT T3.Name) = 2\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:59,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 :  {'chain_of_thought_reasoning': \"To answer the question about the description of the ruling for the card named 'Condemn', I need to locate the table that contains card names and their associated ruling descriptions. The hint provided suggests that the card name is similar to 'Ancestor's Chosen', which indicates that there is a column for card names. The term 'description about the ruling' suggests there is a column specifically for the text of the ruling. First, I will identify the card with the name 'Condemn'. Then, I will retrieve the ruling description for this card. The query will involve selecting the ruling description column from the relevant table where the card name matches 'Condemn'. I will ensure to filter out any null values in the card name and ruling description columns to adhere to the database admin instructions.\", 'SQL': \"SELECT T1.ruling_description FROM Cards T1 WHERE T1.card_name = 'Condemn' AND T1.card_name IS NOT NULL AND T1.ruling_description IS NOT NULL\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [01:08,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 :  {'chain_of_thought_reasoning': \"To answer the question, I need to find out two pieces of information about the molecule identified by 'TR006': the number of double bonds it has and whether it is carcinogenic. From the hint, I know that double bonds are identified by 'bond_type = '=' and carcinogenicity is indicated by the 'label' column where '+' means carcinogenic. I will need to join tables that contain molecule identifiers, bond types, and labels. I will use a WHERE clause to filter the molecule 'TR006', and I will count the occurrences of double bonds. I will use a GROUP BY clause to aggregate results by molecule identifier, ensuring that I only get results for 'TR006'. The final query will select the molecule identifier, the count of double bonds, and the carcinogenicity label.\", 'SQL': \"SELECT T1.molecule_id, COUNT(T2.bond_type) AS double_bonds, T1.label FROM Molecules AS T1 JOIN Bonds AS T2 ON T1.molecule_id = T2.molecule_id WHERE T1.molecule_id = 'TR006' AND T2.bond_type = '=' AND T1.label IS NOT NULL GROUP BY T1.molecule_id\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [01:17,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 :  {'chain_of_thought_reasoning': \"To answer the question, I need to identify the club member who holds the position of 'Secretary'. This requires accessing the member's full name and the college they belong to. The database schema likely includes a table for club members and another for colleges or similar entities. The members table should have columns for first_name, last_name, and a foreign key linking to the college. The position might be stored in the same table or a related table. I will join the necessary tables to access the full name and college information. The query will filter members by the position 'Secretary', join with the college table to get the college name, and select the required fields. I will ensure to handle null values in the sorting or filtering columns and use aliases for clarity in the query.\", 'SQL': \"SELECT T1.first_name || ' ' || T1.last_name AS full_name, T2.college_name FROM Members T1 JOIN Colleges T2 ON T1.college_id = T2.id WHERE T1.position = 'Secretary' AND T1.position IS NOT NULL\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [01:24,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 :  {'chain_of_thought_reasoning': \"To determine the percentage of chemical compounds that form a triple bond, we need to calculate two main values: the total number of compounds and the number of compounds with a triple bond. The 'bond_type' column indicates the type of bond, with '#' representing a triple bond. We can count the total number of distinct compounds and the number of compounds with a triple bond using COUNT and a WHERE clause respectively. Then, to find the percentage, we divide the count of triple-bond compounds by the total count of compounds and multiply by 100. This calculation is performed in a single query using a subquery for clarity and to ensure accuracy.\", 'SQL': \"SELECT (COUNT(CASE WHEN bond_type = '#' THEN 1 ELSE NULL END) * 100.0 / COUNT(*)) AS percent_triple_bond FROM compounds WHERE bond_type IS NOT NULL;\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:33,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 :  {'chain_of_thought_reasoning': \"To answer the question about Francesco Parravicini's potential on a specific date, I need to locate the relevant tables and columns. The player's name and the date are key to filtering the data. First, I'll identify the table that contains player names and link it to any table that contains potential ratings and dates. Assuming a typical schema for player data, there might be a 'players' table with player names and a 'player_stats' or similar table with potential ratings and dates. I'll join these tables on a common key, likely player_id. The filtering will be done on the player's name and the specific date. The SQL query will include a JOIN operation between the players and stats tables, a WHERE clause for the player's name and the date, and a SELECT clause to retrieve only the potential rating as per the instructions.\", 'SQL': \"SELECT T2.potential FROM players T1 JOIN player_stats T2 ON T1.player_id = T2.player_id WHERE T1.player_name = 'Francesco Parravicini' AND T2.date = '2010-08-30 00:00:00'\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [01:42,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 :  {'chain_of_thought_reasoning': \"To answer the question, we need to count the number of male customers living in North Bohemia with an average salary greater than 8000. First, we identify the relevant columns based on the hints: gender (gender = 'M' for male), region (A3 for North Bohemia), and average salary (A11 > 8000). We will filter the data based on these conditions. Since the question asks for a count, we will use the COUNT function. We will also ensure to filter out any null values in the gender, region, and average salary columns to avoid incorrect calculations. The final step is to construct the SQL query using a WHERE clause to filter the data according to the specified conditions and then count the number of relevant entries.\", 'SQL': \"SELECT COUNT(*) FROM customers WHERE gender = 'M' AND A3 = 'North Bohemia' AND A11 > 8000 AND gender IS NOT NULL AND A3 IS NOT NULL AND A11 IS NOT NULL\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [01:51,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 :  {'chain_of_thought_reasoning': \"To answer the question, I need to find the school located in California ('CA') with the lowest latitude, and then retrieve the city and lowest grade of that school along with the school's name. The steps are: 1) Filter schools based on the state being 'CA'. 2) Sort these schools by latitude in ascending order to find the one with the lowest latitude. 3) Select the required columns: city, lowest grade, and school name from the school with the lowest latitude. 4) Use the ORDER BY clause to sort by latitude and LIMIT 1 to get only the school with the lowest latitude. 5) Ensure that the latitude column does not contain null values to avoid errors in sorting.\", 'SQL': \"SELECT T1.city, T1.lowest_grade, T1.school_name FROM Schools T1 WHERE T1.state = 'CA' AND T1.latitude IS NOT NULL ORDER BY T1.latitude ASC LIMIT 1\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [01:59,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 :  {'chain_of_thought_reasoning': \"To solve the query, we need to calculate the percentage of bonds that are double bonds (' = ') among all bonds associated with the molecule 'TR047'. First, we identify the relevant tables and columns: molecule_id and bond_type from a bonds table. We filter the bonds by molecule_id = 'TR047' and then calculate the percentage of those bonds that are double bonds. The percentage calculation involves counting the total number of bonds for 'TR047' and the number of those that are double bonds, then dividing the count of double bonds by the total bond count and multiplying by 100 to get the percentage. We use a CASE statement to conditionally count bonds where bond_type equals ' = '. The result is grouped by molecule_id to ensure the calculation is specific to 'TR047'.\", 'SQL': \"SELECT (SUM(CASE WHEN bond_type = ' = ' THEN 1 ELSE 0 END) * 100.0 / COUNT(*)) AS percent FROM bonds WHERE molecule_id = 'TR047'\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [02:11,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 :  {'chain_of_thought_reasoning': \"To answer the question, I need to find the user who added a bounty of 50 to a post with a title mentioning 'variance'. First, I need to identify the relevant tables and columns. The 'BountyAmount' suggests a table related to bounties, and 'DisplayName' suggests a table related to users. The post title mentioning 'variance' implies a need to filter records based on the title of a post. I will start by identifying the tables: one for bounties, one for posts, and one for users. I will join these tables: bounties to posts (to link bounty to the specific post) and posts to users (to identify the user who made the post). The condition will be set on 'BountyAmount' to be 50 and the post title to include the word 'variance'. I will use LIKE '%variance%' for the title filter. The final output should only include the 'DisplayName' of the user, as per the instructions to select the name when the user is referred to. I will use aliases for clarity in the query.\", 'SQL': \"SELECT U.DisplayName FROM Bounties AS B JOIN Posts AS P ON B.PostId = P.PostId JOIN Users AS U ON P.UserId = U.UserId WHERE B.BountyAmount = 50 AND P.Title LIKE '%variance%'\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [02:20,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 :  {'chain_of_thought_reasoning': \"To answer the question, I need to find the dates when users from Rochester, NY obtained their badges. This involves two main steps: 1) Identifying users from Rochester, NY, which means I need to join the 'users' table with the 'badges' table since the location information is likely in the 'users' table and the badge obtainment dates are in the 'badges' table. 2) Filtering these users and retrieving the dates they obtained badges. I will use SQL JOIN to combine these tables on the user ID, filter by the location 'Rochester, NY', and select the badge date. I will ensure to handle any NULL values in the columns used for filtering and sorting.\", 'SQL': \"SELECT T2.Date FROM Users T1 JOIN Badges T2 ON T1.UserId = T2.UserId WHERE T1.Location = 'Rochester, NY' AND T2.Date IS NOT NULL\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#test candidate generation module with the subsampled test\n",
    "model = \"gpt-4\"\n",
    "num_samples = 1\n",
    "res = []\n",
    "for index, sample in tqdm(enumerate(data)):\n",
    "    task = create_task(sample)\n",
    "    ans = candidate_generation(task=task, retrieved_entities=retrieved_entities[index],\n",
    "                               retrieved_context=retrieved_context[index], selected_schema=selected_schema[index],\n",
    "                               model=model,\n",
    "                               num_samples=num_samples)\n",
    "    res.append(ans)\n",
    "    print(str(index) + \" : \", ans)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T12:46:58.509410Z",
     "start_time": "2024-08-23T12:44:38.183761Z"
    }
   },
   "id": "ffc3c0a2313afb26",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "schema_path = Path('C:/Users/yousf/Bureau/ConvergenceAI/CHESS_Impl/data/test/generated_candidate.json')\n",
    "with open(schema_path, 'w') as f:\n",
    "    json.dump(res, f, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T12:49:32.717700Z",
     "start_time": "2024-08-23T12:49:32.702484Z"
    }
   },
   "id": "46dc23c807d8a742",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cost Estimation per task"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c4a8d9287dcd72"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "PROMPT_PATH = os.getenv(\"PROMPT_ROOT_PATH\") + \"\\\\candidate_generation.txt\"\n",
    "prompt = load_prompt(PROMPT_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-22T10:05:01.943817Z",
     "start_time": "2024-08-22T10:05:01.939524Z"
    }
   },
   "id": "5cae6b6f9579f365",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def tokens_calc(example):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(example))\n",
    "    return num_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-22T10:05:02.325821Z",
     "start_time": "2024-08-22T10:05:02.321403Z"
    }
   },
   "id": "ed9cb2fccf894fbb",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "631"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prompt template tokens \n",
    "tokens_calc(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-22T10:05:03.521031Z",
     "start_time": "2024-08-22T10:05:02.964660Z"
    }
   },
   "id": "e52a0f1e321a497",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "The prompt template has 631 tokens in total, and we have also 3 other variables (Database_Schema,Question and Hint).\n",
    "After i see a formatted prompt example it contains about 2000 tokens (because database_schema will be long)\n",
    "So let's suppose that input tokens is 2000"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33d252fb5933fbd3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "227"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Output tokens estimation from an example \n",
    "output_example = \"\"\"\n",
    "{'chain_of_thought_reasoning': \"First, I identified the relevant columns from the question: CDSCode, County Code, School Type, Low Grade, High Grade, and County Name. Then, I determined that the question is asking for the city location of a high school level school with Lunch Provision 2, whose lowest grade is 9 and the highest grade is 12 in the county of Merced. I used the hint that high school can be represented as EILCode = 'HS'. I joined the frpm and schools tables based on the CDSCode, and then filtered the results to match the conditions specified in the question. Finally, I selected the City column from the schools table, which is the column that provides the city location.\",\n",
    " 'SQL': \"SELECT City FROM schools WHERE EILCode = 'HS' AND County = 'Merced' AND LowGrade = '9' AND HighGrade = '12' AND NSLPProvisionStatus = 'Lunch Provision 2' AND CDSCode IN (SELECT CDSCode FROM frpm WHERE CountyCode = '02');\"}\n",
    "\"\"\"\n",
    "tokens_calc(output_example)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-22T10:06:38.753921Z",
     "start_time": "2024-08-22T10:06:38.698886Z"
    }
   },
   "id": "fa7106b4ff312564",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's suppose the output tokens is 250"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8856a1e42ac656ba"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated price per Task (GPT-4): 0.0275 $\n"
     ]
    }
   ],
   "source": [
    "## Price calculation (just with gpt4 because in this module we don't use gpt3.5) \n",
    "input_price_per_token_gpt4 = 0.01 / 1000\n",
    "output_price_per_token_gpt4 = 0.03 / 1000\n",
    "price_gpt4 = 2000 * input_price_per_token_gpt4 + 250 * output_price_per_token_gpt4\n",
    "print(\"estimated price per Task (GPT-4):\", price_gpt4, \"$\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-22T10:07:28.201308Z",
     "start_time": "2024-08-22T10:07:28.186220Z"
    }
   },
   "id": "77837bff60e65754",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated price with number of retrials of 1:  0.0275\n",
      "The estimated price with number of retrials of 2:  0.055\n",
      "The estimated price with number of retrials of 3:  0.0825\n",
      "The estimated price with number of retrials of 4:  0.11\n",
      "The estimated price with number of retrials of 5:  0.1375\n"
     ]
    }
   ],
   "source": [
    "## in this module there is a number of retrials so let's estimate the price with different number of retrials \n",
    "\n",
    "num_retrials = [1, 2, 3, 4, 5]\n",
    "for num_retrial in num_retrials:\n",
    "    total_price = price_gpt4 * num_retrial\n",
    "    print(\"The estimated price with number of retrials of \" + str(num_retrial) + \": \", total_price)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-22T10:07:52.490764Z",
     "start_time": "2024-08-22T10:07:52.478555Z"
    }
   },
   "id": "9319d65e7029f6e6",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7b39821d84592726"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
