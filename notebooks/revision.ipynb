{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook we will test the revision module "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22501c527f49c824"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## IMPORTs\n",
    "from utils.task import Task\n",
    "import json\n",
    "import os\n",
    "from src.pipeline.candidate_generation import candidate_generation\n",
    "from utils.database_utils.db_info import get_db_schema\n",
    "from dotenv import load_dotenv\n",
    "from utils.prompt import load_prompt\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T13:13:49.055934Z",
     "start_time": "2024-08-23T13:13:46.448281Z"
    }
   },
   "id": "d3ee3500de3a2bd",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to load JSON data\n",
    "def load_json_data(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Function to create task object\n",
    "def create_task(example):\n",
    "    return Task(example)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T13:13:49.065388Z",
     "start_time": "2024-08-23T13:13:49.058019Z"
    }
   },
   "id": "8123f2cb96f2255f",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load the task data\n",
    "filepath = \"C:/Users\\yousf\\Bureau\\ConvergenceAI\\CHESS_Impl\\data/test/subsampled_test.json\"\n",
    "data = load_json_data(filepath)\n",
    "# load the retrieved entities\n",
    "filepath_entities = \"C:/Users\\yousf\\Bureau\\ConvergenceAI\\CHESS_Impl\\data/test/retrieved_entities.json\"\n",
    "retrieved_entities = load_json_data(filepath_entities)\n",
    "# load the retrieved context\n",
    "filepath_context = \"C:/Users\\yousf\\Bureau\\ConvergenceAI\\CHESS_Impl\\data/test/retrieved_context.json\"\n",
    "retrieved_context = load_json_data(filepath_context)\n",
    "# load the selected schema\n",
    "filepath_query = \"C:/Users\\yousf\\Bureau\\ConvergenceAI\\CHESS_Impl\\data/test/generated_candidate.json\"\n",
    "generated_candidate = load_json_data(filepath_query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T13:13:49.092701Z",
     "start_time": "2024-08-23T13:13:49.066397Z"
    }
   },
   "id": "ec40e503f29410ef",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'chain_of_thought_reasoning': \"To answer the question, I need to find the city location of a specific high school in the county of Merced. The school must have a 'Lunch Provision 2' status, and its grade levels should range from 9 to 12. First, I will identify the relevant tables and columns: 'frpm' for the NSLP Provision Status, 'schools' for the city and educational level, and the 'EILCode' to ensure it's a high school. I will join these tables using the 'CDSCode' which is a common key across them. The conditions to filter the data include checking the 'NSLP Provision Status' for 'Lunch Provision 2', 'Low Grade' and 'High Grade' for 9 and 12 respectively, 'County' for 'Merced', and 'EILCode' for 'HS'. The query will join the necessary tables, apply these filters, and select the 'City' column from the 'schools' table.\",\n 'SQL': \"SELECT T3.City FROM frpm T1 JOIN schools T3 ON T1.CDSCode = T3.CDSCode WHERE T1.`NSLP Provision Status` = 'Lunch Provision 2' AND T1.`Low Grade` = '9' AND T1.`High Grade` = '12' AND T3.County = 'Merced' AND T3.EILCode = 'HS'\"}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test candidate generation module with a random sample\n",
    "index = 1\n",
    "example = data[index]\n",
    "task = create_task(example)\n",
    "db_path = os.getenv(\"DB_ROOT_PATH\") + f\"/{task.db_id}/{task.db_id}.sqlite\"\n",
    "model = (\"gpt-4\")\n",
    "ans = candidate_generation(task=task, retrieved_entities=retrieved_entities[index],\n",
    "                           retrieved_context=retrieved_context[index], selected_schema=get_db_schema(db_path),\n",
    "                           model=model,\n",
    "                           num_samples=1)\n",
    "ans"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T13:15:36.433081Z",
     "start_time": "2024-08-23T13:15:21.338518Z"
    }
   },
   "id": "6673724dec9b40e7",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Le Grand',)]\n",
      "[('Le Grand',)]\n"
     ]
    }
   ],
   "source": [
    "from utils.database_utils.execute import execute_query\n",
    "\n",
    "a=execute_query(db_path,ans['SQL'])\n",
    "b=execute_query(db_path,task.SQL)\n",
    "print(a)\n",
    "print(b)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T13:19:02.125006Z",
     "start_time": "2024-08-23T13:19:02.095544Z"
    }
   },
   "id": "53358714fd3228e8",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c7136ae9b275bee3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
